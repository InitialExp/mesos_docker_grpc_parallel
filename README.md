### 功能组件
1. mesos。负责底层基础设施资源的管理，通过编写framework实现对资源的调度与使用。
2. Docker。使用Docker带来的好处包括，
   1. 便利的计算环境管理，能够根据需求定制软件环境，且迁移便捷
   2. 网络管理，利用docker swarm提供的overlay功能，便捷的实现容器的分布式自动组网，支持容器端口与主机物理端口的灵活映射
   3. 支持常用异构计算资源调用，包括CPU、GPU
3. grpc。实现跨语言的远程过程调用



### 基本组件部署与运行步骤
1. 部署mesos，在测试模式下，一台主机作为master节点，其它主机作为agent节点
2. 在各个节点部署docker环境。主要包括安装docker环境和设置私有镜像仓库，导入制作好的基于ubuntu的包含MPI环境的镜像，镜像地址为:https://share.weiyun.com/5vK08CK，并push到私有镜像仓库中
3. 配置docker overlay网络，名称为my-overlay1(可自定义，需要与framework中使用的网络名称保持一致)
4. 在各个节点，根据角色，启动mesos-master和mesos-agent，启动脚本见mesos文件夹。(生产环境中需按照高可用模式配置，多个主机作为主节点，需要配置zookeeper)
5. 运行官方的mesos测试程序，保证程序的正常运行

### 平台如何实现后端计算资源的管理和并行计算
1. 当用户登录或启动任务触发时，为用户分配相应规模的计算资源。具体通过启动framework程序实现，framework会接受所需规模的计算资源，并：
   1. 在网关节点上启动一个容器，用于运行并行程序的主进程，并且申请占用一个网络端口与容器内固定的grpc server端口映射，用于提供grpc server服务
   2. 在其它计算节点上，启动相应规模的容器，和网关节点上的共同构成一个分布式计算集群环境(见mesos相关中的framework示例,python2程序)，并自动生成提供了各个节点的主机名列表
2. 程序相关
   1. 并行后端计算程序，如分布式参数调优、并行求解器，在实现时，需包含grpc server功能，并保证相应的grpc server进程在网关节点上运行。(见超参数调优例子，基于mpi4py实现了分布式调优并提供grpc server功能)
   2. 当用户需要进行某项具体的任务时，需要调用后端进行并行计算时，则在第一步建立的分布式计算环境上，启动相应的并行程序。启动方法见程序文件夹中的grpc_start.sh
   3. 程序启动后，前端程序可以通过网关节点上的之前分配的端口，访问调用后端的分布式计算程序，得到结果。客户端示例见程序文件夹下的client.py（python3）
   4. 完成当前任务后，结束后端运行的并行计算程序，此时当前用户的分布式计算环境仍然保留，等待之后继续运行其它的并行程序
3. 当用户退出登录或其它机制触发，则mesos停止framework，释放当前用户占用的资源

### 各层面的改进讨论
1. 资源管理层。使用mesos实现，也可替换为k8s或其它资源管理框架，根据需求和具体使用场景，则相应的任务调度方法需要进行修改。
2. 任务调度层。
   1. 动态资源的分配。当前为分配固定数目的资源，没有考虑多用户下资源的协调。未来可通过改进framework，用一个framework替代多个framework统一进行任务调度，或在mesos中为不同的用户、任务类型，设置不同的角色，利用mesos的资源强占支持实现。
   2. docker数量和主机间数量cpu数量之间的映射分配关系。由于当前使用的mpich不支持rankfile功能，所以当前docker容器数量与cpu核数相同，且与进程数量相同。这不一定是最好的映射方式和进程拓扑结构，如可将mpich替换为openmpi，病利用rankfile,则可减少docker启动容器的数量。
3. 容器和软件框架层。包括相应库的安装和替换，当前安装的库还过少。
4. 服务层。服务发现机制的实现，更好的管理不同用户间的多个grpc服务。
5. 整体服务逻辑针对现实需求的改进。

